{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa87c9f-dd5d-4cf7-a9f4-50de4b36ce40",
   "metadata": {},
   "source": [
    "## Классификация изображений\n",
    "### Вводные слова\n",
    "Задача классификации изображений - это одна из ключевых задач в области компьютерного зрения и машинного обучения. Она заключается в том, чтобы разработать модель, способную автоматически определить, к какому классу или категории принадлежит данное изображение. Классификация используется в следующих задачах: классификация спектрограмм музыкальных записей для выявления предпочтений конкретного пользователя, классификация изображений для автоматической идентификации людей на фотографиях, кластеризация покупок пользователя в интернет-магазине для формирования целевой рекламы, и так далее\n",
    "### Рекомендации\n",
    "Работу лучше выполнять в среде Google Colab, поскольку потребуется осуществлять вычисления на видеокарте. В Colab в меню нажмите на Изменить->Настройки блокнота и выберите доступный GPU. Это позволит использовать для обучения CUDA\n",
    "### Цель работы и задачи\n",
    "В данной работе мы разработаем модель, для предсказания класса на датасете cifar-10. Ниже будет представлена baseline модель, основываясь на которой вы можете строить свою модель для классификации\n",
    "\\\n",
    "Задачи, которые вам нужно решить в работе:\n",
    "\\\n",
    "Обязательные:\n",
    "- Построить распределение классов в данных\n",
    "- Подготовить данные и обучить baseline-модель на датасете\n",
    "- Оценить качество модели\n",
    "- Написать свою модель и обучить ее\n",
    "\n",
    "Желательные:\n",
    "- Подумать об архитектуре модели, быть может стоит сделать ее глубже, добавить боковые связи и т.д.\n",
    "- Задуматься об аугментации\n",
    "- Попробовать transfer-learning\n",
    "\n",
    "\\\n",
    "\\\n",
    "Ваша работа будет оцениваться исходя из 2 факторов:\n",
    "- контрольная метрика\n",
    "- протокол исследования, которым и будет служить этот Jupyter-Notebook\n",
    "\n",
    "\\\n",
    "Максимальный балл за работу - 20.\n",
    "\\\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e69704-f4ce-4b25-98ce-5e98630a389d",
   "metadata": {},
   "source": [
    "## Baseline-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b4054-5e95-4ce5-96b0-e0817d64e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Импорт основную библиотеку PyTorch для работы с нейронными сетями\n",
    "from tqdm import tqdm  # Импорти tqdm для отображения прогресс-баров\n",
    "import torch.nn as nn  # Импорт модуля nn для создания слоев нейронной сети\n",
    "import torch.optim as optim  # Импорт модуль оптимизации\n",
    "import torchvision  # Импорт torchvision для работы с изображениями и датасетами\n",
    "import torchvision.transforms as transforms  # Импорт трансформации для обработки изображений\n",
    "import matplotlib.pyplot as plt  # Импорт matplotlib для визуализации данных\n",
    "import numpy as np  # Импортир NumPy для работы с массивами\n",
    "from sklearn.model_selection import train_test_split  # Импорт функцию для разделения данных на обучающие и тестовые наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6abc6-ee2d-408a-8521-11c9602e63ce",
   "metadata": {},
   "source": [
    "Обучать мы будем, разумеется, на cuda, поэтому, создадим переменную device, которая будет зависеть от того, доступна ли видеокарта для вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8d12f-a0c3-44e7-912f-59485c4146c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка устройства (GPU или CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  # Проверяем, доступен ли GPU, иначе используем CPU\n",
    "print(f'Running on {device}')  # Вывод, на каком устройстве будет выполняться код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc0bb5-d955-4516-a47d-16b29c29a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчета числа параметров в модели\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Считаем количество обучаемых параметров модели\n",
    "\n",
    "# Определение класса модели\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # Конструктор класса, принимающий количество классов\n",
    "        super(Baseline, self).__init__()  # Инициализация базового класса nn.Module\n",
    "        # Сверточные слои\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)  # Первый сверточный слой\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)  # Второй сверточный слой\n",
    "        # Полносвязные слои\n",
    "        self.fc1 = nn.Linear(in_features=32 * 8 * 8, out_features=128)  # Первый полносвязный слой\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)  # Второй полносвязный слой, выходной слой\n",
    "\n",
    "    def forward(self, x):  # Метод для прямого прохода через сеть\n",
    "        # Прямой проход через сверточные слои с активацией ReLU\n",
    "        x = torch.relu(self.conv1(x))  # Применяем ReLU к первому сверточному слою\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)  # Применяем максимальную пулинг-операцию\n",
    "        x = torch.relu(self.conv2(x))  # Применяем ReLU ко второму сверточному слою\n",
    "        x = torch.max_pool2d(x, kernel_size=2, stride=2)  # Применяем максимальную пулинг-операцию\n",
    "        # Вытягивание в одномерный вектор для полносвязных слоев\n",
    "        x = x.view(x.size(0), -1)  # Изменяем размерность тензора\n",
    "        # Прямой проход через полносвязные слои\n",
    "        x = torch.relu(self.fc1(x))  # Применяем ReLU к первому полносвязному слою\n",
    "        x = self.fc2(x)  # Проход через выходной слой\n",
    "        return x  # Возвращаем выходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a75636-3a12-42d0-a050-51b79b9b76ba",
   "metadata": {},
   "source": [
    "Загрузим данные, построим диаграммы для распределения классов и посмотрим на сами картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552abcaa-ae9a-4f77-a0b7-05311057d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование изображений в формат torch.Tensor\n",
    "transform = transforms.ToTensor()  # Преобразование изображений в тензоры\n",
    "\n",
    "# Загрузка датасетов для обучения и тестирования\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)  # Загрузка обучающего датасета CIFAR-10\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)  # Загрузка тестового датасета CIFAR-10\n",
    "\n",
    "# Получение меток классов\n",
    "class_labels = train_dataset.classes  # Получаем названия классов\n",
    "class_counts = np.array([0] * len(class_labels))  # Инициализируем массив для подсчета количества изображений в каждом классе\n",
    "\n",
    "# Подсчет количества изображений в каждом классе\n",
    "for _, label in train_dataset:  # Проходим по всему обучающему датасету\n",
    "    class_counts[label] += 1  # Увеличиваем счетчик для соответствующего класса\n",
    "\n",
    "class_counts = class_counts / class_counts.sum() * 100  # Преобразуем в процентное соотношение\n",
    "\n",
    "# Построение диаграммы распределения классов\n",
    "plt.figure(figsize=(10, 8))  # Устанавливаем размер фигуры для графика\n",
    "plt.bar(class_labels, class_counts)  # Строим столбчатую диаграмму\n",
    "plt.xlabel('Классы')  # Подпись оси X\n",
    "plt.ylabel('Количество изображений, %')  # Подпись оси Y\n",
    "plt.title('Распределение классов в датасете CIFAR-10')  # Заголовок графика\n",
    "plt.xticks(rotation=45)  # Поворачиваем метки по оси X для удобства чтения\n",
    "plt.tight_layout()  # Автоматически подгоняем параметры графика\n",
    "plt.show()  # Отображаем график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4505ddd-6bdb-42eb-9d83-c78091a824b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение случайных изображений из обучающего датасета\n",
    "indices = np.random.choice(len(train_dataset), 9, replace=False)  # Выбор 9 случайных индексов\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))  # Создаем сетку для отображения изображений\n",
    "for i, ax in enumerate(axes.flat):  # Проходим по всем осям в сетке\n",
    "    image, label = train_dataset[indices[i]]  # Получаем изображение и метку по индексу\n",
    "    image = image.numpy().transpose((1, 2, 0))  # Переводим изображение из формата (C, H, W) в (H, W, C)\n",
    "    ax.imshow(image)  # Отображаем изображение\n",
    "    ax.set_title(f'Label: {label}')  # Устанавливаем заголовок с меткой класса\n",
    "    ax.axis('off')  # Отключаем оси для лучшего отображения\n",
    "plt.show()  # Отображаем изображения\n",
    "\n",
    "# Разделение на обучающую и валидационную выборки\n",
    "train_size = int(0.8 * len(train_dataset))  # Определяем размер обучающего набора (80%)\n",
    "val_size = len(train_dataset) - train_size  # Определяем размер валидационного набора\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=val_size, random_state=42, shuffle=True)  # Разделяем данные на обучающую и валидационную выборки\n",
    "\n",
    "# Создание DataLoader'ов для загрузки данных\n",
    "batch_size = 64  # Устанавливаем размер пакета\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Создание DataLoader для обучающего набора\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)  # Создание DataLoader для валидационного набора\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # Создание DataLoader для тестового набора\n",
    "\n",
    "# Гиперпараметры\n",
    "learning_rate = 0.001  # Устанавливаем скорость обучения\n",
    "num_epochs = 10  # Устанавливаем количество эпох для обучения\n",
    "model = Baseline().to(device)  # Создаем экземпляр модели и переносим ее на устройство (GPU или CPU)\n",
    "print('Model params: ', count_parameters(model))  # Выводим количество параметров модели\n",
    "\n",
    "# Определяем функцию потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()  # Используем функцию потерь кросс-энтропии для многоклассовой классификации\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Используем оптимизатор Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d176f3c-b153-4ed8-8963-b268f7b5972f",
   "metadata": {},
   "source": [
    "Сделайте вывод о сбалансированности датасета:\n",
    "\\\n",
    "Исходя из этого, какие метрики будем применять для оценки качества модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411c3aa-4894-40f4-9f2e-5cab17405d05",
   "metadata": {},
   "source": [
    "Напишем функции train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd72a1-ff5a-493e-be70-da9af9efcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обучения модели\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    model.train()  # Устанавливаем модель в режим обучения\n",
    "    train_loss_history = []  # Список для хранения истории потерь на обучающем наборе\n",
    "    train_acc_history = []  # Список для хранения истории точности на обучающем наборе\n",
    "    val_loss_history = []  # Список для хранения истории потерь на валидационном наборе\n",
    "    val_acc_history = []  # Список для хранения истории точности на валидационном наборе\n",
    "    \n",
    "    for epoch in range(epochs):  # Проходим по эпохам\n",
    "        running_loss = 0.0  # Инициализируем переменную для накопления потерь\n",
    "        correct = 0  # Инициализируем счетчик правильных предсказаний\n",
    "        total = 0  # Инициализируем общий счетчик\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=100, desc='Train epoch {}/{}'.format(epoch + 1, epochs))  # Создание прогресс-бар для обучения\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in pbar:  # Проходим по пакетам данных\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Переносим данные на устройство\n",
    "            optimizer.zero_grad()  # Зануляем градиенты для оптимизатора\n",
    "            outputs = model(inputs)  # Получаем предсказания модели\n",
    "            loss = criterion(outputs, labels)  # Вычисляем потери\n",
    "            \n",
    "            loss.backward()  # Обратный проход для вычисления градиентов\n",
    "            optimizer.step()  # Шаг оптимизации\n",
    "            \n",
    "            running_loss += loss.item()  # Накопление потерь\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Получаем предсказанные классы\n",
    "            total += labels.size(0)  # Обновляем общий счетчик\n",
    "            correct += (predicted == labels).sum().item()  # Обновляем счетчик правильных предсказаний\n",
    "            pbar.set_postfix({'loss': '{:.4f}'.format(running_loss / (batch_idx + 1)), 'accuracy': '{:.4f}'.format(correct / total)})  # Обновляем прогресс-бар с потерями и точностью\n",
    "        \n",
    "        train_loss_history.append(running_loss / len(train_loader))  # Сохраняем средние потери на обучающем наборе\n",
    "        train_acc_history.append(correct / total)  # Сохраняем точность на обучающем наборе\n",
    "\n",
    "        # Валидация\n",
    "        correct = 0  # Счетчик для правильных предсказаний на валидационном наборе\n",
    "        total = 0  # Общий счетчик на валидационном наборе\n",
    "        test_loss = 0.0  # Инициализируем переменную для накопления потерь на валидационном наборе\n",
    "        pbar = tqdm(enumerate(val_loader), total=len(val_loader), ncols=100, desc='Val {}/{}'.format(epoch + 1, epochs))  # Создаем прогресс-бар для валидации\n",
    "        \n",
    "        with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "            for batch_idx, (inputs, labels) in pbar:  # Проходим по пакетам валидационных данных\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Переносим данные на устройство\n",
    "                outputs = model(inputs)  # Получаем предсказания модели\n",
    "                loss = criterion(outputs, labels)  # Вычисляем потери\n",
    "                test_loss += loss.item()  # Накопление потерь\n",
    "                _, predicted = torch.max(outputs.data, 1)  # Получаем предсказанные классы\n",
    "                total += labels.size(0)  # Обновляем общий счетчик\n",
    "                correct += (predicted == labels).sum().item()  # Обновляем счетчик правильных предсказаний\n",
    "                pbar.set_postfix({'loss': '{:.4f}'.format(test_loss / (batch_idx + 1)), 'accuracy': '{:.4f}'.format(correct / total)})  # Обновляем прогресс-бар\n",
    "        \n",
    "        val_loss_history.append(test_loss / len(val_loader))  # Сохраняем средние потери на валидационном наборе\n",
    "        val_acc_history.append(correct / total)  # Сохраняем точность на валидационном наборе\n",
    "        \n",
    "    return train_loss_history, train_acc_history, val_loss_history, val_acc_history  # Возвращаем историю потерь и точности\n",
    "\n",
    "# Функция для тестирования модели\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()  # Устанавливаем модель в режим оценки\n",
    "    correct = 0  # Счетчик для правильных предсказаний\n",
    "    total = 0  # Общий счетчик\n",
    "    test_loss = 0.0  # Инициализация переменную для накопления потерь\n",
    "    with torch.no_grad():  # Отключаем градиенты для тестирования\n",
    "        for inputs, labels in test_loader:  # Проходим по тестовым данным\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Переносим данные на устройство\n",
    "            outputs = model(inputs)  # Получаем предсказания модели\n",
    "            loss = criterion(outputs, labels)  # Вычисляем потери\n",
    "            test_loss += loss.item()  # Накопление потерь\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Получаем предсказанные классы\n",
    "            total += labels.size(0)  # Обновляем общий счетчик\n",
    "            correct += (predicted == labels).sum().item()  # Обновляем счетчик правильных предсказаний\n",
    "\n",
    "    accuracy = correct / total  # Вычисление точности\n",
    "    average_loss = test_loss / len(test_loader)  # Вычисляем средние потери\n",
    "    \n",
    "    return accuracy, average_loss  # Возвращаем точность и средние потери\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba5730-5f22-4715-b181-5d3878fa12bc",
   "metadata": {},
   "source": [
    "Сделайте разделение на train и val\n",
    "\\\n",
    "Зачем так делать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ab630-8224-4d2f-9d02-79ab163d3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history = train(model, train_loader, val_loader, criterion, optimizer, device, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0108c36-a287-410a-a4db-ec018503f113",
   "metadata": {},
   "source": [
    "Создайте Dataloader'ы и настройте гиперпараметры, оптимизатор и функцию потерь\n",
    "\\\n",
    "Какой оптимизатор будете использовать и почему, а какую loss-функцию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a9cbd-5969-4bac-8fa0-9f5415082b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графики обучения\n",
    "epochs = range(1, len(train_loss_history) + 1)  # Создаем диапазон для оси X\n",
    "\n",
    "# График функции потерь на тренировочных данных\n",
    "plt.figure(figsize=(12, 5))  # Устанавливаем размер графика\n",
    "plt.subplot(1, 2, 1)  # Создаем подграфик для потерь\n",
    "plt.plot(epochs, train_loss_history, 'b', label='Train Loss')  # График потерь на обучающем наборе\n",
    "plt.plot(epochs, val_loss_history, 'r', label='Validation Loss')  # График потерь на валидационном наборе\n",
    "plt.title('Train and Validation Loss')  # Заголовок графика\n",
    "plt.xlabel('Epochs')  # Подпись оси X\n",
    "plt.ylabel('Loss')  # Подпись оси Y\n",
    "plt.legend()  # Отображаем легенду"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ff197-828a-4eda-ac8d-6a07d9597db5",
   "metadata": {},
   "source": [
    "Обучите модель и постройте графики обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7508531-309f-4e77-8c98-0c8e41005eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка тестовой метрики на тестовых данных\n",
    "test_acc, test_loss = test(model, test_loader, criterion, device)  # Тестируем модель на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcb17e-73b3-451c-8298-835029326057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графики обучения\n",
    "epochs = range(1, len(train_loss_history) + 1)  # Создаем диапазон для оси X\n",
    "\n",
    "# График функции потерь на тренировочных данных\n",
    "plt.figure(figsize=(12, 5))  # Устанавливаем размер графика\n",
    "plt.subplot(1, 2, 1)  # Создаем подграфик для потерь\n",
    "plt.plot(epochs, train_loss_history, 'b', label='Train Loss')  # График потерь на обучающем наборе\n",
    "plt.plot(epochs, val_loss_history, 'r', label='Validation Loss')  # График потерь на валидационном наборе\n",
    "plt.title('Train and Validation Loss')  # Заголовок графика\n",
    "plt.xlabel('Epochs')  # Подпись оси X\n",
    "plt.ylabel('Loss')  # Подпись оси Y\n",
    "plt.legend()  # Отображаем легенду\n",
    "\n",
    "# График точности на валидационных данных\n",
    "plt.subplot(1, 2, 2)  # Создаем подграфик для точности\n",
    "plt.plot(epochs, train_acc_history, 'b', label='Train Accuracy')  # График точности на обучающем наборе\n",
    "plt.plot(epochs, val_acc_history, 'g', label='Validation Accuracy')  # График точности на валидационном наборе\n",
    "plt.title('Validation Accuracy')  # Заголовок графика\n",
    "plt.xlabel('Epochs')  # Подпись оси X\n",
    "plt.ylabel('Accuracy')  # Подпись оси Y\n",
    "plt.legend()  # Отображаем легенду\n",
    "\n",
    "plt.tight_layout()  # Автоматически подгоняем параметры графиков\n",
    "plt.show()  # Отображаем графики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195b688-6baa-4c71-bc0c-5f90d7eed6da",
   "metadata": {},
   "source": [
    "Сделайте выводы о качестве обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff061f53-e474-4cb4-b34d-45f14546c400",
   "metadata": {},
   "source": [
    "Оцените тестовую метрику на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c54f83-e0a6-4e1c-87c7-b129028cae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Loss: {:.4f}\\nTest Accuracy: {:.4f}'.format(test_loss, test_acc))  # Вывод потерь и точности на тестовом наборе\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b78b24-c338-4e42-81ce-7c120d8fd420",
   "metadata": {},
   "source": [
    "## Что дальше?\n",
    "Теперь, когда у вас есть все необходимое - экспериментируйте. Можете изменить все что угодно, креативность поощряется. Используйте новые модели, loss-функции, аугментацию, ансамбли, выдумывайте все, что сможете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c373039-62ab-441a-84bc-473d3fa726d2",
   "metadata": {},
   "source": [
    "## Критерии оценки\n",
    "Accuracy - на тестовых данных\n",
    "- $Accuracy \\leq 0.67$ - 0 баллов\n",
    "- $0.67 < Accuracy \\leq 0.72$ - 2 балла\n",
    "- $0.72 < Accuracy \\leq 0.77$ - 4 балла\n",
    "- $0.77 < Accuracy \\leq 0.82$ - 6 баллов\n",
    "- $0.82 < Accuracy \\leq 0.87$ - 8 баллов\n",
    "- $Accuracy > 0.87$ - 10 баллов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
